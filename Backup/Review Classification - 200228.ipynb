{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"tocheading\">Table of Contents</h1>\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hotel Review Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project uses the hotel review data vectorized in the previous phase to build descriptive and predictive models for hotel ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import timeit\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the data that is already split to train and test sets is loaded as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_dataframe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below the high-level information of the data are shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13651 entries, 0 to 13650\n",
      "Columns: 2587 entries, Additional_Number_of_Scoring to Reviewer_Score\n",
      "dtypes: float64(2587)\n",
      "memory usage: 269.4 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Additional_Number_of_Scoring</th>\n",
       "      <th>Average_Score</th>\n",
       "      <th>Review_Total_Negative_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews</th>\n",
       "      <th>Review_Total_Positive_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews_Reviewer_Has_Given</th>\n",
       "      <th>days_since_review</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>Review_Month</th>\n",
       "      <th>...</th>\n",
       "      <th>p_working</th>\n",
       "      <th>p_world</th>\n",
       "      <th>p_worth</th>\n",
       "      <th>p_wouldn</th>\n",
       "      <th>p_year</th>\n",
       "      <th>p_years</th>\n",
       "      <th>p_yes</th>\n",
       "      <th>p_young</th>\n",
       "      <th>p_yummy</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>902.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>51.494308</td>\n",
       "      <td>-0.175558</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1190.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5180.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>51.514879</td>\n",
       "      <td>-0.160650</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.425849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>299.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1361.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>672.0</td>\n",
       "      <td>51.521009</td>\n",
       "      <td>-0.123097</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>87.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>51.499749</td>\n",
       "      <td>-0.161524</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>317.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1458.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>51.516114</td>\n",
       "      <td>-0.174952</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2587 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Additional_Number_of_Scoring  Average_Score  \\\n",
       "0                         220.0            9.1   \n",
       "1                        1190.0            7.5   \n",
       "2                         299.0            8.3   \n",
       "3                          87.0            9.0   \n",
       "4                         317.0            7.6   \n",
       "\n",
       "   Review_Total_Negative_Word_Counts  Total_Number_of_Reviews  \\\n",
       "0                               20.0                    902.0   \n",
       "1                                5.0                   5180.0   \n",
       "2                               81.0                   1361.0   \n",
       "3                               17.0                    355.0   \n",
       "4                               14.0                   1458.0   \n",
       "\n",
       "   Review_Total_Positive_Word_Counts  \\\n",
       "0                               21.0   \n",
       "1                               23.0   \n",
       "2                               27.0   \n",
       "3                               13.0   \n",
       "4                                0.0   \n",
       "\n",
       "   Total_Number_of_Reviews_Reviewer_Has_Given  days_since_review        lat  \\\n",
       "0                                         1.0              275.0  51.494308   \n",
       "1                                         6.0              481.0  51.514879   \n",
       "2                                         4.0              672.0  51.521009   \n",
       "3                                         7.0              412.0  51.499749   \n",
       "4                                         1.0              499.0  51.516114   \n",
       "\n",
       "        lng  Review_Month  ...  p_working  p_world  p_worth  p_wouldn  p_year  \\\n",
       "0 -0.175558          11.0  ...        0.0      0.0      0.0       0.0     0.0   \n",
       "1 -0.160650           4.0  ...        0.0      0.0      0.0       0.0     0.0   \n",
       "2 -0.123097          10.0  ...        0.0      0.0      0.0       0.0     0.0   \n",
       "3 -0.161524           6.0  ...        0.0      0.0      0.0       0.0     0.0   \n",
       "4 -0.174952           3.0  ...        0.0      0.0      0.0       0.0     0.0   \n",
       "\n",
       "    p_years  p_yes  p_young  p_yummy  Reviewer_Score  \n",
       "0  0.000000    0.0      0.0      0.0             1.0  \n",
       "1  0.425849    0.0      0.0      0.0             1.0  \n",
       "2  0.000000    0.0      0.0      0.0             0.0  \n",
       "3  0.000000    0.0      0.0      0.0             1.0  \n",
       "4  0.000000    0.0      0.0      0.0             0.0  \n",
       "\n",
       "[5 rows x 2587 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test_dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3413 entries, 0 to 3412\n",
      "Columns: 2587 entries, Additional_Number_of_Scoring to Reviewer_Score\n",
      "dtypes: float64(2587)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df = train_df.sample(frac=0.1, random_state=42)\n",
    "#test_df = test_df.sample(frac=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Additional_Number_of_Scoring</th>\n",
       "      <th>Average_Score</th>\n",
       "      <th>Review_Total_Negative_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews</th>\n",
       "      <th>Review_Total_Positive_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews_Reviewer_Has_Given</th>\n",
       "      <th>days_since_review</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>Review_Month</th>\n",
       "      <th>...</th>\n",
       "      <th>p_worked</th>\n",
       "      <th>p_working</th>\n",
       "      <th>p_world</th>\n",
       "      <th>p_worth</th>\n",
       "      <th>p_wouldn</th>\n",
       "      <th>p_year</th>\n",
       "      <th>p_years</th>\n",
       "      <th>p_yes</th>\n",
       "      <th>p_young</th>\n",
       "      <th>p_yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>902.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>51.494308</td>\n",
       "      <td>-0.175558</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1190.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5180.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>51.514879</td>\n",
       "      <td>-0.160650</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.425849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>299.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1361.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>672.0</td>\n",
       "      <td>51.521009</td>\n",
       "      <td>-0.123097</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>87.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>51.499749</td>\n",
       "      <td>-0.161524</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>317.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1458.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>51.516114</td>\n",
       "      <td>-0.174952</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2586 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Additional_Number_of_Scoring  Average_Score  \\\n",
       "0                         220.0            9.1   \n",
       "1                        1190.0            7.5   \n",
       "2                         299.0            8.3   \n",
       "3                          87.0            9.0   \n",
       "4                         317.0            7.6   \n",
       "\n",
       "   Review_Total_Negative_Word_Counts  Total_Number_of_Reviews  \\\n",
       "0                               20.0                    902.0   \n",
       "1                                5.0                   5180.0   \n",
       "2                               81.0                   1361.0   \n",
       "3                               17.0                    355.0   \n",
       "4                               14.0                   1458.0   \n",
       "\n",
       "   Review_Total_Positive_Word_Counts  \\\n",
       "0                               21.0   \n",
       "1                               23.0   \n",
       "2                               27.0   \n",
       "3                               13.0   \n",
       "4                                0.0   \n",
       "\n",
       "   Total_Number_of_Reviews_Reviewer_Has_Given  days_since_review        lat  \\\n",
       "0                                         1.0              275.0  51.494308   \n",
       "1                                         6.0              481.0  51.514879   \n",
       "2                                         4.0              672.0  51.521009   \n",
       "3                                         7.0              412.0  51.499749   \n",
       "4                                         1.0              499.0  51.516114   \n",
       "\n",
       "        lng  Review_Month  ...  p_worked  p_working  p_world  p_worth  \\\n",
       "0 -0.175558          11.0  ...       0.0        0.0      0.0      0.0   \n",
       "1 -0.160650           4.0  ...       0.0        0.0      0.0      0.0   \n",
       "2 -0.123097          10.0  ...       0.0        0.0      0.0      0.0   \n",
       "3 -0.161524           6.0  ...       0.0        0.0      0.0      0.0   \n",
       "4 -0.174952           3.0  ...       0.0        0.0      0.0      0.0   \n",
       "\n",
       "   p_wouldn  p_year   p_years  p_yes  p_young  p_yummy  \n",
       "0       0.0     0.0  0.000000    0.0      0.0      0.0  \n",
       "1       0.0     0.0  0.425849    0.0      0.0      0.0  \n",
       "2       0.0     0.0  0.000000    0.0      0.0      0.0  \n",
       "3       0.0     0.0  0.000000    0.0      0.0      0.0  \n",
       "4       0.0     0.0  0.000000    0.0      0.0      0.0  \n",
       "\n",
       "[5 rows x 2586 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df.iloc[:,:-1]\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    1.0\n",
       "2    0.0\n",
       "3    1.0\n",
       "4    0.0\n",
       "Name: Reviewer_Score, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_df.iloc[:,-1]\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.iloc[:,:-1]\n",
    "y_test = test_df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.8272654018020658\n",
      "Test Accuracy:  0.7896278933489599\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state=42).fit(X_train, y_train)\n",
    "print('Train Accuracy: ', lr.score(X_train, y_train))\n",
    "print('Test Accuracy: ', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({'Feature':X_train.columns, 'Coefficient': lr.coef_[0]})\n",
    "coef_df.sort_values(by='Coefficient', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2522</td>\n",
       "      <td>p_upgraded</td>\n",
       "      <td>2.059033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1719</td>\n",
       "      <td>p_amazing</td>\n",
       "      <td>2.037435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1978</td>\n",
       "      <td>p_fantastic</td>\n",
       "      <td>1.781315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1228</td>\n",
       "      <td>n_perfect</td>\n",
       "      <td>1.706760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2308</td>\n",
       "      <td>p_professional</td>\n",
       "      <td>1.698139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1561</td>\n",
       "      <td>n_tiny</td>\n",
       "      <td>-1.797868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>722</td>\n",
       "      <td>n_dated</td>\n",
       "      <td>-1.839281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>753</td>\n",
       "      <td>n_dirty</td>\n",
       "      <td>-2.228388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1366</td>\n",
       "      <td>n_room</td>\n",
       "      <td>-2.232058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1481</td>\n",
       "      <td>n_staff</td>\n",
       "      <td>-2.625180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2177 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature  Coefficient\n",
       "2522      p_upgraded     2.059033\n",
       "1719       p_amazing     2.037435\n",
       "1978     p_fantastic     1.781315\n",
       "1228       n_perfect     1.706760\n",
       "2308  p_professional     1.698139\n",
       "...              ...          ...\n",
       "1561          n_tiny    -1.797868\n",
       "722          n_dated    -1.839281\n",
       "753          n_dirty    -2.228388\n",
       "1366          n_room    -2.232058\n",
       "1481         n_staff    -2.625180\n",
       "\n",
       "[2177 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df = coef_df[coef_df.Feature.str.contains('^[n,p]_')]\n",
    "word_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2522</td>\n",
       "      <td>p_upgraded</td>\n",
       "      <td>2.059033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1719</td>\n",
       "      <td>p_amazing</td>\n",
       "      <td>2.037435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1978</td>\n",
       "      <td>p_fantastic</td>\n",
       "      <td>1.781315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1228</td>\n",
       "      <td>n_perfect</td>\n",
       "      <td>1.706760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2308</td>\n",
       "      <td>p_professional</td>\n",
       "      <td>1.698139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1972</td>\n",
       "      <td>p_fabulous</td>\n",
       "      <td>1.644790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2005</td>\n",
       "      <td>p_friendliness</td>\n",
       "      <td>1.591903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2271</td>\n",
       "      <td>p_perfect</td>\n",
       "      <td>1.561669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1955</td>\n",
       "      <td>p_excellent</td>\n",
       "      <td>1.513672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>n_fault</td>\n",
       "      <td>1.504318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2168</td>\n",
       "      <td>p_loved</td>\n",
       "      <td>1.475253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2440</td>\n",
       "      <td>p_stay</td>\n",
       "      <td>1.462111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1851</td>\n",
       "      <td>p_comfort</td>\n",
       "      <td>1.452769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1761</td>\n",
       "      <td>p_beautiful</td>\n",
       "      <td>1.402817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2460</td>\n",
       "      <td>p_superb</td>\n",
       "      <td>1.331682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2573</td>\n",
       "      <td>p_wonderful</td>\n",
       "      <td>1.310531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1792</td>\n",
       "      <td>p_brilliant</td>\n",
       "      <td>1.293120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1079</td>\n",
       "      <td>n_lovely</td>\n",
       "      <td>1.286296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1284</td>\n",
       "      <td>n_problem</td>\n",
       "      <td>1.210570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2459</td>\n",
       "      <td>p_super</td>\n",
       "      <td>1.198559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>876</td>\n",
       "      <td>n_food</td>\n",
       "      <td>-1.292642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>n_dark</td>\n",
       "      <td>-1.295371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>652</td>\n",
       "      <td>n_cold</td>\n",
       "      <td>-1.334239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1907</td>\n",
       "      <td>p_did</td>\n",
       "      <td>-1.335351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1164</td>\n",
       "      <td>n_night</td>\n",
       "      <td>-1.349581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>522</td>\n",
       "      <td>n_basic</td>\n",
       "      <td>-1.363402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2240</td>\n",
       "      <td>p_ok</td>\n",
       "      <td>-1.409050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1367</td>\n",
       "      <td>n_rooms</td>\n",
       "      <td>-1.416473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370</td>\n",
       "      <td>n_rude</td>\n",
       "      <td>-1.435789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>528</td>\n",
       "      <td>n_bed</td>\n",
       "      <td>-1.500571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1187</td>\n",
       "      <td>n_old</td>\n",
       "      <td>-1.594807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1490</td>\n",
       "      <td>n_star</td>\n",
       "      <td>-1.608265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1209</td>\n",
       "      <td>n_overpriced</td>\n",
       "      <td>-1.646616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1562</td>\n",
       "      <td>n_tired</td>\n",
       "      <td>-1.650406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1259</td>\n",
       "      <td>n_poor</td>\n",
       "      <td>-1.745596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1561</td>\n",
       "      <td>n_tiny</td>\n",
       "      <td>-1.797868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>722</td>\n",
       "      <td>n_dated</td>\n",
       "      <td>-1.839281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>753</td>\n",
       "      <td>n_dirty</td>\n",
       "      <td>-2.228388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1366</td>\n",
       "      <td>n_room</td>\n",
       "      <td>-2.232058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1481</td>\n",
       "      <td>n_staff</td>\n",
       "      <td>-2.625180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature  Coefficient\n",
       "2522      p_upgraded     2.059033\n",
       "1719       p_amazing     2.037435\n",
       "1978     p_fantastic     1.781315\n",
       "1228       n_perfect     1.706760\n",
       "2308  p_professional     1.698139\n",
       "1972      p_fabulous     1.644790\n",
       "2005  p_friendliness     1.591903\n",
       "2271       p_perfect     1.561669\n",
       "1955     p_excellent     1.513672\n",
       "850          n_fault     1.504318\n",
       "2168         p_loved     1.475253\n",
       "2440          p_stay     1.462111\n",
       "1851       p_comfort     1.452769\n",
       "1761     p_beautiful     1.402817\n",
       "2460        p_superb     1.331682\n",
       "2573     p_wonderful     1.310531\n",
       "1792     p_brilliant     1.293120\n",
       "1079        n_lovely     1.286296\n",
       "1284       n_problem     1.210570\n",
       "2459         p_super     1.198559\n",
       "876           n_food    -1.292642\n",
       "720           n_dark    -1.295371\n",
       "652           n_cold    -1.334239\n",
       "1907           p_did    -1.335351\n",
       "1164         n_night    -1.349581\n",
       "522          n_basic    -1.363402\n",
       "2240            p_ok    -1.409050\n",
       "1367         n_rooms    -1.416473\n",
       "1370          n_rude    -1.435789\n",
       "528            n_bed    -1.500571\n",
       "1187           n_old    -1.594807\n",
       "1490          n_star    -1.608265\n",
       "1209    n_overpriced    -1.646616\n",
       "1562         n_tired    -1.650406\n",
       "1259          n_poor    -1.745596\n",
       "1561          n_tiny    -1.797868\n",
       "722          n_dated    -1.839281\n",
       "753          n_dirty    -2.228388\n",
       "1366          n_room    -2.232058\n",
       "1481         n_staff    -2.625180"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_df = word_df.head(20).append(word_df.tail(20))\n",
    "twenty_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = scaler.fit_transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.54 s ± 161 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "scale_lr = LogisticRegression(solver='lbfgs', random_state=42)\n",
    "scale_lr.fit(X_train_scale, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.866676433960882\n",
      "Test Accuracy:  0.7497802519777322\n"
     ]
    }
   ],
   "source": [
    "print('Train Accuracy: ', scale_lr.score(X_train_scale, y_train))\n",
    "print('Test Accuracy: ', scale_lr.score(X_test_scale, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression model achieved 75% accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficeint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2511</td>\n",
       "      <td>p_truly</td>\n",
       "      <td>0.362584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2114</td>\n",
       "      <td>p_kindly</td>\n",
       "      <td>0.329085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1719</td>\n",
       "      <td>p_amazing</td>\n",
       "      <td>0.310931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1955</td>\n",
       "      <td>p_excellent</td>\n",
       "      <td>0.292555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2213</td>\n",
       "      <td>p_movies</td>\n",
       "      <td>0.282158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2308</td>\n",
       "      <td>p_professional</td>\n",
       "      <td>0.276714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1078</td>\n",
       "      <td>n_loved</td>\n",
       "      <td>0.266326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2046</td>\n",
       "      <td>p_half</td>\n",
       "      <td>0.266018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016</td>\n",
       "      <td>p_future</td>\n",
       "      <td>0.264394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2099</td>\n",
       "      <td>p_ironing</td>\n",
       "      <td>0.238970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1978</td>\n",
       "      <td>p_fantastic</td>\n",
       "      <td>0.238240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2522</td>\n",
       "      <td>p_upgraded</td>\n",
       "      <td>0.234762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2271</td>\n",
       "      <td>p_perfect</td>\n",
       "      <td>0.230162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2410</td>\n",
       "      <td>p_smile</td>\n",
       "      <td>0.229315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>856</td>\n",
       "      <td>n_feet</td>\n",
       "      <td>0.225242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1761</td>\n",
       "      <td>p_beautiful</td>\n",
       "      <td>0.222012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1741</td>\n",
       "      <td>p_attention</td>\n",
       "      <td>0.221863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2252</td>\n",
       "      <td>p_outstanding</td>\n",
       "      <td>0.210144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1990</td>\n",
       "      <td>p_fi</td>\n",
       "      <td>0.209550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1693</td>\n",
       "      <td>p_02</td>\n",
       "      <td>0.208196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1367</td>\n",
       "      <td>n_rooms</td>\n",
       "      <td>-0.195906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>722</td>\n",
       "      <td>n_dated</td>\n",
       "      <td>-0.202327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>735</td>\n",
       "      <td>n_deluxe</td>\n",
       "      <td>-0.204522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>528</td>\n",
       "      <td>n_bed</td>\n",
       "      <td>-0.205577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1449</td>\n",
       "      <td>n_smelly</td>\n",
       "      <td>-0.206303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>n_impression</td>\n",
       "      <td>-0.206986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1490</td>\n",
       "      <td>n_star</td>\n",
       "      <td>-0.210036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1777</td>\n",
       "      <td>p_board</td>\n",
       "      <td>-0.220754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2565</td>\n",
       "      <td>p_wi</td>\n",
       "      <td>-0.225395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1158</td>\n",
       "      <td>n_negative</td>\n",
       "      <td>-0.238588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1678</td>\n",
       "      <td>n_won</td>\n",
       "      <td>-0.246730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370</td>\n",
       "      <td>n_rude</td>\n",
       "      <td>-0.248320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>753</td>\n",
       "      <td>n_dirty</td>\n",
       "      <td>-0.269847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1226</td>\n",
       "      <td>n_peeling</td>\n",
       "      <td>-0.270779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1481</td>\n",
       "      <td>n_staff</td>\n",
       "      <td>-0.304271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1366</td>\n",
       "      <td>n_room</td>\n",
       "      <td>-0.371637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>n_lamp</td>\n",
       "      <td>-0.373563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1008</td>\n",
       "      <td>n_joke</td>\n",
       "      <td>-0.402323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>n_premier</td>\n",
       "      <td>-0.403465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>545</td>\n",
       "      <td>n_black</td>\n",
       "      <td>-0.898809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature  Coefficeint\n",
       "2511         p_truly     0.362584\n",
       "2114        p_kindly     0.329085\n",
       "1719       p_amazing     0.310931\n",
       "1955     p_excellent     0.292555\n",
       "2213        p_movies     0.282158\n",
       "2308  p_professional     0.276714\n",
       "1078         n_loved     0.266326\n",
       "2046          p_half     0.266018\n",
       "2016        p_future     0.264394\n",
       "2099       p_ironing     0.238970\n",
       "1978     p_fantastic     0.238240\n",
       "2522      p_upgraded     0.234762\n",
       "2271       p_perfect     0.230162\n",
       "2410         p_smile     0.229315\n",
       "856           n_feet     0.225242\n",
       "1761     p_beautiful     0.222012\n",
       "1741     p_attention     0.221863\n",
       "2252   p_outstanding     0.210144\n",
       "1990            p_fi     0.209550\n",
       "1693            p_02     0.208196\n",
       "1367         n_rooms    -0.195906\n",
       "722          n_dated    -0.202327\n",
       "735         n_deluxe    -0.204522\n",
       "528            n_bed    -0.205577\n",
       "1449        n_smelly    -0.206303\n",
       "980     n_impression    -0.206986\n",
       "1490          n_star    -0.210036\n",
       "1777         p_board    -0.220754\n",
       "2565            p_wi    -0.225395\n",
       "1158      n_negative    -0.238588\n",
       "1678           n_won    -0.246730\n",
       "1370          n_rude    -0.248320\n",
       "753          n_dirty    -0.269847\n",
       "1226       n_peeling    -0.270779\n",
       "1481         n_staff    -0.304271\n",
       "1366          n_room    -0.371637\n",
       "1030          n_lamp    -0.373563\n",
       "1008          n_joke    -0.402323\n",
       "1270       n_premier    -0.403465\n",
       "545          n_black    -0.898809"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df = pd.DataFrame({'Feature':X_train.columns, 'Coefficeint': scale_lr.coef_[0]})\n",
    "coef_df.sort_values(by='Coefficeint', ascending=False, inplace=True)\n",
    "word_df = coef_df[coef_df.Feature.str.contains('^[n,p]_')]\n",
    "twenty_df = word_df.head(20).append(word_df.tail(20))\n",
    "twenty_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principle Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# principle component analysis\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.9)\n",
    "X_train_scale_pca = pca.fit_transform(X_train_scale)\n",
    "X_test_scale_pca = pca.transform(X_test_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.25 s ± 139 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pca_lr = LogisticRegression(solver='lbfgs', random_state=42).fit(X_train_scale_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.8507069079188337\n",
      "Test Accuracy:  0.762086141224729\n"
     ]
    }
   ],
   "source": [
    "print('Train Accuracy: ', pca_lr.score(X_train_scale_pca, y_train))\n",
    "print('Test Accuracy: ', pca_lr.score(X_test_scale_pca, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training accuracy has decreased because the model have less information to work with; however, test accuracy has improved because the discarded dimensions had more noise to introduce error than predictive information to increase accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - computation time\n",
    "The computation time reduced from 6.7 sec to 3.6 sec because PCA reduced the amount of info to be processed. The computation time is cut to almost half with only losing 10% of the info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# + improved test accuracy \n",
    "# - lost interpreability\n",
    "Even though PCA improved test accuracy, the coefficients of the model are not interpretable anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=30).fit(X_train_scale_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6177569408834518\n",
      "0.5977146205684148\n"
     ]
    }
   ],
   "source": [
    "print(knn.score(X_train_scale_pca, y_train))\n",
    "print(knn.score(X_test_scale_pca, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "remainder_sample_df = train_df.sample(frac=0.1, random_state=42)\n",
    "test_sample_df = test_df.sample(frac=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_remainder_sample = remainder_sample_df.iloc[:,:-1]\n",
    "y_remainder_sample = remainder_sample_df.iloc[:,-1]\n",
    "X_test_sample = test_sample_df.iloc[:,:-1]\n",
    "y_test_sample = test_sample_df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data to training data and validation data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_sample, X_valid_sample, y_train_sample, y_valid_sample = train_test_split(X_remainder_sample, y_remainder_sample, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data with standard scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_sample_scale = scaler.fit_transform(X_train_sample)\n",
    "X_valid_sample_scale = scaler.transform(X_valid_sample)\n",
    "X_test_sample_scale = scaler.transform(X_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# principle component analysis\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=200)\n",
    "X_train_sample_scale_pca = pca.fit_transform(X_train_sample_scale)\n",
    "X_valid_sample_scale_pca = pca.transform(X_valid_sample_scale)\n",
    "X_test_sample_scale_pca = pca.transform(X_test_sample_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.9 ms ± 1.54 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=30).fit(X_train_sample_scale_pca, y_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "query data dimension must match training data dimension",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-25a13bcd7d10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_sample_scale_pca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid_sample_scale_pca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_sample_scale_pca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    355\u001b[0m         \"\"\"\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    452\u001b[0m                 delayed_query(\n\u001b[0;32m    453\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n\u001b[1;32m--> 454\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m             )\n\u001b[0;32m    456\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[1;34m(tree, data, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \"\"\"\n\u001b[1;32m--> 291\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn\\neighbors\\binary_tree.pxi\u001b[0m in \u001b[0;36msklearn.neighbors.kd_tree.BinaryTree.query\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: query data dimension must match training data dimension"
     ]
    }
   ],
   "source": [
    "print(knn.score(X_train_sample_scale_pca, y_train_sample))\n",
    "print(knn.score(X_valid_sample_scale_pca, y_valid_sample))\n",
    "print(knn.score(X_test_sample_scale_pca, y_test_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - data point reduction effect\n",
    "# train/test/both\n",
    "10% sample has reduced the computation time. Both train and test sets should get sampled in order to reduced because in nearest neighbors method for each test point each train points get evaluated to obtain the test score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#+ computation time \n",
    "#- test accuracy \n",
    "\n",
    "The advantage of reduced number of data points is that computation time has reduced; however, the disadvantage is that test accuracy has decreased as well. In the early prototyping stage, reducing number of data points saves a lot of time in trials after which the complete dataset can be employed to achieve maximum performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_accuracies = []\n",
    "valid_accuracies = []\n",
    "\n",
    "for n in range(1,30):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n).fit(X_train_sample_scale_pca, y_train_sample)\n",
    "    train_accuracies.append(knn.score(X_train_sample_scale_pca, y_train_sample))\n",
    "    valid_accuracies.append(knn.score(X_valid_sample_scale_pca, y_valid_sample))    \n",
    "\n",
    "plt.plot(range(1,30), train_accuracies)\n",
    "plt.plot(range(1,30), valid_accuracies)\n",
    "plt.legend(['train', 'valid'])\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Classification Accuracy')\n",
    "\n",
    "print(range(1,30)[np.argmax(valid_accuracies)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - leakage \n",
    "The problem with splitting the data to train and test after TF-IDF vectorization is that in this process many words existing in the test set appear as columns in train set affecting the test accuracy due to information leakage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier().fit(X_train_scale_pca, y_train)\n",
    "print('Train Accuracy: ', dt.score(X_train_scale_pca, y_train))\n",
    "print('Test Accuracy: ', dt.score(X_test_scale_pca, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_accuracies = []\n",
    "valid_accuracies = []\n",
    "\n",
    "param_range = range(1,20)\n",
    "\n",
    "for n in param_range:\n",
    "    dt = DecisionTreeClassifier(max_depth=n).fit(X_train_sample_scale_pca, y_train_sample)\n",
    "    train_accuracies.append(dt.score(X_train_sample_scale_pca, y_train_sample))\n",
    "    valid_accuracies.append(dt.score(X_valid_sample_scale_pca, y_valid_sample))    \n",
    "\n",
    "plt.plot(param_range, train_accuracies)\n",
    "plt.plot(param_range, valid_accuracies)\n",
    "plt.legend(['train', 'valid'])\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Classification Accuracy')\n",
    "print(range(1,30)[np.argmax(valid_accuracies)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#- Decision over KNN 1\n",
    "#- Decision over KNN 2\n",
    "\n",
    "There are two great advantages of decision tree over nearest neighbors. First, decision tree provides better interpretations of features involved in the classification. Furthermore, decision trees have less prediction time than nearest neighbores because they get trained once and then only evaluated in time of prediction while for nearest neighbores every single training data points get checked upon predition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#- validation purpose\n",
    "\n",
    "The validation set is used to optimize hyperparameters of the algorithms before it is tested on the test set as a measure of its performance in the real world. If the performance on the test and validation sets are close, the real world performance is most likely on the same level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "dt = DecisionTreeClassifier()\n",
    "scores = cross_val_score(lr, X_remainder_sample, y_remainder_sample, cv = 5)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cv_accuracies = []\n",
    "\n",
    "for n in range(1,20):\n",
    "    dt = DecisionTreeClassifier(max_depth=n)\n",
    "    cv_accuracies.append((cross_val_score(dt, X_remainder_sample, y_remainder_sample, cv = 5)).mean())\n",
    "\n",
    "plt.plot(param_range, cv_accuracies)\n",
    "print(cv_accuracies[range(1,20)[np.argmax(cv_accuracies)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "dt = DecisionTreeClassifier(max_depth=range(1,20)[np.argmax(cv_accuracies)]).fit(X_train_sample_scale_pca, y_train_sample)\n",
    "y_pred = dt.predict(X_test_sample_scale_pca)\n",
    "confusion_matrix(y_test_sample, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#- confusion matrix explanation \n",
    "\n",
    "The confusion matrix is 2-by-2 because there are two classes. The number of correct classifications are higher than incorrect classifications. There are more false positives than false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- feature explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.Positive_Ratio = (X_train.Review_Total_Positive_Word_Counts - X_train.Review_Total_Negative_Word_Counts) / \\\n",
    "(X_train.Review_Total_Positive_Word_Counts + X_train.Review_Total_Negative_Word_Counts)\n",
    "X_train.Positive_Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new feature to sample set\n",
    "X_remainder_sample.Positive_Ratio = (X_remainder_sample.Review_Total_Positive_Word_Counts - X_remainder_sample.Review_Total_Negative_Word_Counts) / \\\n",
    "(X_remainder_sample.Review_Total_Positive_Word_Counts + X_remainder_sample.Review_Total_Negative_Word_Counts)\n",
    "X_remainder_sample.Positive_Ratio\n",
    "\n",
    "# scale data with standard scaler\n",
    "scaler = StandardScaler()\n",
    "X_remainder_sample_scale = scaler.fit_transform(X_remainder_sample)\n",
    "\n",
    "\n",
    "'''\n",
    "# principle component analysis\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2587 )\n",
    "X_train_sample_scale_pca = pca.fit_transform(X_train_sample_scale)\n",
    "X_valid_sample_scale_pca = pca.transform(X_valid_sample_scale)\n",
    "X_test_sample_scale_pca = pca.transform(X_test_sample_scale)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_accuracies = []\n",
    "param_range = range(1,20)\n",
    "for n in param_range:\n",
    "    dt = DecisionTreeClassifier(max_depth=n)\n",
    "    cv_accuracies.append((cross_val_score(dt, X_remainder_sample, y_remainder_sample, cv = 5)).mean())\n",
    "\n",
    "\n",
    "plt.plot(param_range, cv_accuracies)\n",
    "print(range(1,20)[np.argmax(cv_accuracies)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(cv_accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - accuracy comparision\n",
    "The accuracy has slighlty as a result of the new info provided to the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
